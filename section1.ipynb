{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"stressed\"\n",
    "# for i in range(1, len(string)+1):\n",
    "#     print(string[-i], end='')\n",
    "string[::-1] # 上2行の処理をスライスを使うと簡単にかける iterable[start:stop:step(<0は逆順)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー"
     ]
    }
   ],
   "source": [
    "string = \"パタトクカシーー\"\n",
    "mask:list[int] = [1, 3, 5, 7]\n",
    "for i in mask:\n",
    "    print(string[i-1], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー"
     ]
    }
   ],
   "source": [
    "string1 = \"パトカー\"\n",
    "string2 = \"タクシー\"\n",
    "for i in range(len(string1)):\n",
    "    print(string1[i], end='')\n",
    "    print(string2[i], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "# 単語ごとにリストに格納する\n",
    "words_list = []\n",
    "words_list = sentence.split(' ')\n",
    "# ','や'.'などの記号を取り除く\n",
    "# 下のコードだとeは値渡しになるのでスコープ外では変更が元に戻ってしまう\n",
    "# for e in words_list:\n",
    "    # e = e.replace(',' ,'')\n",
    "    # e = e.replace('.', '')\n",
    "# 正しくは以下\n",
    "for i in range(len(words_list)):\n",
    "    words_list[i] = words_list[i].replace(',', '')\n",
    "    words_list[i] = words_list[i].replace('.', '')\n",
    "# print(words_list)\n",
    "answer:list[int] = []\n",
    "for e in words_list:\n",
    "    answer.append(len(e))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "put_first = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "# 単語ごとにリストに格納する\n",
    "words_list = [e.replace(',', '').replace('.', '') for e in sentence.split(' ')] # 03.円周率 コード3~13行目を内包表記を使って書いた。\n",
    "# print(words_list)\n",
    "answer:dict[str, int] = {}\n",
    "for i in range(len(words_list)):\n",
    "    if i+1 in put_first:\n",
    "        answer[words_list[i][0]] = i+1\n",
    "    else:\n",
    "        answer[words_list[i][0]+words_list[i][1]] = i+1\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram:  [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "文字bi-gram:  ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def n_gram(seq, n:int):\n",
    "    ret:list[str] = []\n",
    "    for i in range(len(seq) - n + 1):\n",
    "        ret.append(seq[i:i+n])\n",
    "    return ret\n",
    "\n",
    "sentence = \"I am an NLPer\"\n",
    "print(\"単語bi-gram: \", n_gram(sentence.split(), 2))\n",
    "print(\"文字bi-gram: \", n_gram(sentence, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XとYの和集合:  {'pa', 'ar', 'ag', 'ad', 'ra', 'ap', 'di', 'gr', 'se', 'is', 'ph'}\n",
      "XとYの積集合:  {'pa', 'ra', 'ar', 'ap'}\n",
      "XとYの差集合:  {'se', 'is', 'di', 'ad'}\n",
      "'se'というbi-gramがXに含まれる?:  True\n",
      "'se'というbi-gramがYに含まれる?:  False\n"
     ]
    }
   ],
   "source": [
    "X = set(n_gram(\"paraparaparadise\", 2))\n",
    "Y = set(n_gram(\"paragraph\", 2))\n",
    "print(\"XとYの和集合: \", X | Y)\n",
    "print(\"XとYの積集合: \", X & Y)\n",
    "print(\"XとYの差集合: \", X - Y)\n",
    "print(\"\\'se\\'というbi-gramがXに含まれる?: \", 'se' in X)\n",
    "print(\"\\'se\\'というbi-gramがYに含まれる?: \", 'se' in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template_message(x, y, z) -> str:\n",
    "    return str(x) + '時の' + str(y) + 'は' + str(z)\n",
    "\n",
    "print(template_message(x=12, y=\"気温\", z=22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．  \n",
    "\n",
    "+ 英小文字ならば(219 - 文字コード)の文字に置換  \n",
    "+ その他の文字はそのまま出力  \n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an NLPer!\n",
      "-> I zn zm NLPvi!\n",
      "-> I am an NLPer!\n"
     ]
    }
   ],
   "source": [
    "def cipher(S:str) -> str:\n",
    "    new:list[str] = []\n",
    "    for s in S:\n",
    "        if ord('a') <= ord(s) <= ord('z'):\n",
    "            s = chr(219 - ord(s))\n",
    "        new.append(s)\n",
    "    return ''.join(new)\n",
    "\n",
    "message = \"I am an NLPer!\"\n",
    "encrypted_message = cipher(message)\n",
    "decrypted_message = cipher(encrypted_message)\n",
    "print(f\"{message}\\n-> {encrypted_message}\\n-> {decrypted_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cuol'dnt bliveee that I culod aautlcly uatrndnsed what I was reniadg : the pohneanmel poewr of the haumn mind .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sentence = \"I couldn\\'t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "words_list = sentence.split()\n",
    "new = []\n",
    "for e in words_list:\n",
    "    if len(e) > 4:\n",
    "        chr_list = [c for c in e] # 単語の文字ごとのリスト\n",
    "        chr_list.pop(-1) # 末尾の文字をリストから削除\n",
    "        chr_list.pop(0) # 先頭の文字をリストから削除\n",
    "        random.shuffle(chr_list)\n",
    "        chr_list.insert(0, e[0]) # 先頭の文字をリストの先頭に追加\n",
    "        chr_list.append(e[-1]) # 末尾の文字をリストの末尾に追加\n",
    "        new.append(''.join(chr_list))\n",
    "    else:\n",
    "        new.append(e)\n",
    "print(' '.join(new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef3c131357060280e2ef04985c04dd4d2f7a8402c5a2a2b1b77aee1cdb996bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
